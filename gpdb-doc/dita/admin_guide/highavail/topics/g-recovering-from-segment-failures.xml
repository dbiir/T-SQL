<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<topic id="topic14">
  <title>Recovering From Segment Failures</title>
  <body>
    <p>Segment host failures usually cause multiple segment failures: all primary or mirror segment
      instances on the host are marked as down and nonoperational. If mirroring is not enabled and a
      segment goes down, the system automatically becomes nonoperational.</p>
    <p>A segment instance can fail for several reasons, such as a host failure, network failure, or
      disk failure. When a segment instance fails, its status is marked as <i>down</i> in the
      Greenplum Database system catalog, and its mirror is activated in <i>change tracking</i> mode.
      In order to bring the failed segment instance back into operation again, you must first
      correct the problem that made it fail in the first place, and then recover the segment
      instance in Greenplum Database using <codeph>gprecoverseg</codeph>.</p>
    <p>If a segment host is not recoverable and you have lost one or more segment instances with
      mirroring enabled, you can attempt to recover a segment instance from its mirror. See <xref
        href="g-when-a-segment-host-is-not-recoverable.xml"/>. You can also recreate your Greenplum
      Database system from backup files. See <xref href="../../managing/backup-main.xml"/>. </p>
    <section id="ki155642">
      <title>To recover with mirroring enabled</title>
      <ol>
        <li id="ki155643">Ensure you can connect to the segment host from the master host. For
          example:<codeblock>$ ping <i>failed_seg_host_address</i></codeblock>
        </li>
        <li id="ki155645">Troubleshoot the problem that prevents the master host from connecting to
          the segment host. For example, the host machine may need to be restarted or replaced.</li>
        <li id="ki155646">After the host is online and you can connect to it, run the <codeph><xref
              href="../../../utility_guide/ref/gprecoverseg.xml"
            >gprecoverseg</xref></codeph> utility from the master host to reactivate the failed
          segment instances and start the process of sycnronizing the master and mirror instances.
          For example:<codeblock>$ gprecoverseg</codeblock>
        </li>
        <li id="ki158500">The recovery process brings up the failed segments and identifies the
          changed files that need to be synchronized. The process can take some time; wait for the
          process to complete.</li>
        <li id="ki164382">After <codeph>gprecoverseg</codeph> completes, the system goes into
            <i>Resynchronizing</i> mode and begins copying the changed files. This process runs in
          the background while the system is online and accepting database requests.</li>
        <li id="ki158504">When the resynchronization process completes, the system state is
            <i>Synchronized</i>. Run the <codeph><xref
              href="../../../utility_guide/ref/gpstate.xml" type="topic" format="dita"
              >gpstate</xref></codeph> utility to verify the status of the resynchronization
          process:<codeblock>$ gpstate -m</codeblock></li>
      </ol>
      <note otherprops="pivotal"> If incremental recovery was not successful and the down segment
        instance data is not corrupted, contact Pivotal Support. </note>
    </section>
    <section id="ki155666">
      <title>To return all segments to their preferred role</title>
      <p>When a primary segment instance goes down, the mirror activates and becomes the primary
        segment. After running <codeph>gprecoverseg</codeph>, the currently active segment instance
        remains the primary and the failed segment becomes the mirror. The segment instances are not
        returned to the preferred role that they were given at system initialization time. This
        means that the system could be in a potentially unbalanced state if segment hosts have more
        active segments than is optimal for top system performance. To check for unbalanced segments
        and rebalance the system, run:</p>
      <codeblock>$ gpstate -e</codeblock>
      <p>All segments must be online and fully synchronized to rebalance the system. Database
        sessions remain connected during rebalancing, but queries in progress are canceled and
        rolled back. </p>
      <ol>
        <li id="ki165540">Run <codeph>gpstate -m</codeph> to ensure all mirrors are
            <i>Synchronized</i>. <codeblock>$ gpstate -m</codeblock>
        </li>
        <li id="ki165577">If any mirrors are in <i>Resynchronizing</i> mode, wait for them to
          complete.</li>
        <li id="ki165591">Run <codeph>gprecoverseg</codeph> with the <codeph>-r</codeph> option to
          return the segments to their preferred roles.<codeblock>$ gprecoverseg -r</codeblock>
        </li>
        <li id="ki166668">After rebalancing, run <codeph>gpstate -e</codeph> to confirm all segments
          are in their preferred roles.<codeblock>$ gpstate -e</codeblock>
        </li>
      </ol>
    </section>
    <section id="sec-df">
      <title>To recover from a double fault</title>
      <p>In a double fault, both a primary segment and its mirror are down. This can occur if
        hardware failures on different segment hosts happen simultaneously. Greenplum Database is
        unavailable if a double fault occurs. </p>
      <p>To recover from a double fault.</p>
      <ol>
        <li>Troubleshoot the problem that caused the double fault and ensure that the segment hosts
          are operational and are accessible from the master host.</li>
        <li id="ki165670">Restart Greenplum Database. The <codeph><xref
              href="../../../utility_guide/ref/gpstop.xml" type="topic" format="dita"
              >gpstop</xref></codeph> option <codeph>-r</codeph> stops and restarts the
          system.<codeblock>$ gpstop -r</codeblock></li>
        <li id="ki165671">After the system restarts, run <codeph>gprecoverseg</codeph> to reactivate
          the failed segment instances.<codeblock>$ gprecoverseg</codeblock>
          <note otherprops="pivotal"> If incremental recovery was not successful and the down
            segment instance data is not corrupted, contact Pivotal Support. </note></li>
        <li id="ki165709">After <codeph>gprecoverseg</codeph> completes, use
            <codeph>gpstate</codeph> to check the status of your mirrors and ensure the segment
          instances have gone from <i>Resynchronizing</i> mode to <i>Synchronized</i>
          mode:<codeblock>$ gpstate -m </codeblock></li>
        <li id="ki165730">If you still have segment instances in <i>change tracking</i> mode, you
          can run <codeph>gprecoverseg</codeph> with the <codeph>-F</codeph> option to perform a
          full segment recovery.
          <note type="warning">A full recovery deletes the data directory of the down segment
            instance before copying the data from the active (current primary) segment instance.
            Before performing a full recovery, ensure that the segment failure did not cause data
            corruption and that any host segment disk issues have been
          fixed.</note><codeblock>$ gprecoverseg -F</codeblock></li>
        <li>If needed, return segment instances to their preferred role. See <xref
            href="#topic14/ki155666" format="dita"/>.</li>
      </ol>
    </section>
    <section>
      <title><ph>To recover without mirroring enabled</ph></title>
      <ol id="ol_lb2_rkq_kr">
        <li id="ki155667">Ensure you can connect to the segment host from the master host. For
          example:<codeblock>$ ping <varname>failed_seg_host_address</varname></codeblock>
        </li>
        <li id="ki155669">Troubleshoot the problem that is preventing the master host from
          connecting to the segment host. For example, the host machine may need to be
          restarted.</li>
        <li id="ki155670">After the host is online, verify that you can connect to it and restart
          Greenplum Database. The <codeph>gpstop</codeph> option <codeph>-r</codeph> stops and
          restarts the system:<codeblock>$ gpstop -r </codeblock></li>
        <li id="ki155681">Run the <codeph>gpstate</codeph> utility to verify that all segment
          instances are online:<codeblock>$ gpstate</codeblock>
        </li>
      </ol>
    </section>
  </body>
</topic>
