<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<topic id="topic9">
  <title>Detecting a Failed Segment</title>
  <body>
    <p>With segment mirroring enabled, Greenplum Database automatically fails over to a mirror
      segment instance when a primary segment instance goes down. Provided one segment instance is
      online per portion of data, users may not realize a segment is down. If a transaction is in
      progress when a fault occurs, the in-progress transaction rolls back and restarts
      automatically on the reconfigured set of segments. The <codeph><xref
          href="../../../utility_guide/ref/gpstate.xml#topic1" type="topic"
          format="dita"/></codeph> utility can be used to identify failed segments. The utility
      displays information from the catalog tables including <codeph><xref
          href="../../../ref_guide/system_catalogs/gp_segment_configuration.xml"/></codeph>. </p>
    <p>If the entire Greenplum Database system becomes nonoperational due to a segment failure (for
      example, if mirroring is not enabled or not enough segments are online to access all user
      data), users will see errors when trying to connect to a database. The errors returned to the
      client program may indicate the failure. For example:</p>
    <codeblock>ERROR: All segment databases are unavailable</codeblock>
    <section>
      <title>How a Segment Failure is Detected and Managed</title>
      <p>On the Greenplum Database master host, the Postgres <codeph>postmaster</codeph> process
        forks a fault probe process, <codeph>ftsprobe</codeph>. This is also known as the FTS (Fault
        Tolerance Server) process. The <codeph>postmaster</codeph> process restarts the FTS if it
        fails. </p>
      <p dir="ltr">The FTS runs in a loop with a sleep interval between each cycle. On each loop,
        the FTS probes each primary segment instance by making a TCP socket connection to the
        segment instance using the hostname and port registered in the
          <codeph>gp_segment_configuration</codeph> table. If the connection succeeds, the segment
        performs a few simple checks and reports back to the FTS. The checks include executing a
          <codeph>stat</codeph> system call on critical segment directories and checking for
        internal faults in the segment instance. If no issues are detected, a positive reply is sent
        to the FTS and no action is taken for that segment instance. </p>
      <p dir="ltr">If the connection cannot be made, or if a reply is not received in the timeout
        period, then a retry is attempted for the segment instance. If the configured maximum number
        of probe attempts fail, the FTS probes the segment's mirror to ensure that it is up, and
        then updates the <codeph>gp_segment_configuration</codeph> table, marking the primary
        segment "down" and setting the mirror to act as the primary. The FTS updates the
            <codeph><xref href="../../../ref_guide/system_catalogs/gp_configuration_history.xml"
          /></codeph> table with the operations performed.</p>
      <p dir="ltr">When there is only an active primary segment and the corresponding mirror is
        down, the primary goes into the <i>not synchronizing</i> state and continues logging
        database changes, so the mirror can be synchronized without performing a full copy of data
        from the primary to the mirror.</p>
      <p>Running the <codeph>gpstate</codeph> utility with the <codeph>-e</codeph> option displays
        any issues with a primary or mirror segment instances. Other <codeph>gpstate</codeph>
        options that display information about all primary or mirror segment instances such as
          <codeph>-m</codeph> (mirror instance information) and <codeph>-c</codeph> (primary and
        mirror configuration information) also display information about primary and mirror issues. </p>
      <p dir="ltr">You can also can see the mode: <codeph>s</codeph> (synchronizing) or
          <codeph>n</codeph> (not synchronizing) for each segment instance, as well as the status
          <codeph>u</codeph> (up) or <codeph>d</codeph> (down), in the
          <codeph>gp_segment_configuration</codeph> table. </p>
      <p dir="ltr">The <codeph><xref href="../../../utility_guide/ref/gprecoverseg.xml"
          /></codeph> utility is used to bring up a mirror that is down. By default,
          <codeph>gprecoverseg</codeph> performs an incremental recovery, placing the mirror into
        synchronizing mode, which starts to replay the recorded changes from the primary onto the
        mirror. If the incremental recovery cannot be completed, the recovery fails and
          <codeph>gprecoverseg</codeph> should be run again with the <codeph>-F</codeph> option, to
        perform full recovery. This causes the primary to copy all of the data to the mirror.</p>
      <p>After a segment instance has been recovered, the <codeph>gpstate -e</codeph> command might
        list primary and mirror segment instances that are switched. This indicates that the system
        is not balanced (the primary and mirror instances are not in their originally configured
        roles). If a system is not balanced, there might be skew resulting from the number of active
        primary segment instances on segment host systems.</p>
      <p dir="ltr">The <codeph>gp_segment_configuration</codeph> table has columns
          <codeph>role</codeph> and <codeph>preferred_role</codeph>. These can have values of either
          <codeph>p</codeph> for primary or <codeph>m</codeph> for mirror. The <codeph>role</codeph>
        column shows the segment instance current role and the <codeph>preferred_role</codeph> shows
        the original role of the segment instance. </p>
      <p dir="ltr">In a balanced system, the <codeph>role</codeph> and
          <codeph>preferred_role</codeph> matches for all segment instances. When they do not match
        the system is not balanced. To rebalance the cluster and bring all the segments into their
        preferred role, run the <codeph>gprecoverseg</codeph> command with the <codeph>-r</codeph>
        option.</p>
    </section>
    <section>
      <title>Simple Failover and Recovery Example</title>
      <p dir="ltr">Consider a single primary-mirror segment instance pair where the primary segment
        has failed over to the mirror. The following table shows the segment instance preferred
        role, role, mode, and status from <codeph>gp_segment_configuration</codeph> table before
        beginning recovery of the failed primary segment. </p>
      <p>You can also run <codeph>gpstate -e</codeph> to display any issues with a primary or mirror
        segment instances. </p>
      <table frame="all" rowsep="1" colsep="1" id="table_hdk_jst_fgb">
        <tgroup cols="5">
          <colspec colname="c1" colnum="1" colwidth="1.0*"/>
          <colspec colname="c2" colnum="2" colwidth="1.0*"/>
          <colspec colname="c3" colnum="3" colwidth="1.0*"/>
          <colspec colname="c4" colnum="4" colwidth="1.0*"/>
          <colspec colname="c5" colnum="5" colwidth="1.0*"/>
          <thead>
            <row>
              <entry/>
              <entry><codeph>preferred_role</codeph></entry>
              <entry><codeph>role</codeph></entry>
              <entry><codeph>mode</codeph></entry>
              <entry><codeph>status</codeph></entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>Primary</entry>
              <entry><codeph>p</codeph><p>(primary)</p></entry>
              <entry><codeph>m</codeph><p>(mirror)</p></entry>
              <entry><codeph>n</codeph><p>(not synchronizing)</p></entry>
              <entry><codeph>d</codeph><p>(down)</p></entry>
            </row>
            <row>
              <entry>Mirror</entry>
              <entry><codeph>m</codeph><p>(mirror)</p></entry>
              <entry><codeph>p</codeph><p>(primary)</p></entry>
              <entry><codeph>n</codeph><p>(not synchronizing)</p></entry>
              <entry><codeph>u</codeph><p>(up)</p></entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <p>The segment instance roles are not in their preferred roles, and the primary is down. The
        mirror is up, the role is now primary, and it is not synchronizing because its mirror, the
        failed primary, is down. After fixing issues with the segment host and primary segment
        instance, you use <codeph>gprecoverseg</codeph> to prepare failed segment instances for
        recovery and initiate synchronization between the primary and mirror instances. </p>
      <p>Once <codeph>gprecoverseg</codeph> has completed, the segments are in the states shown in
        the following table where the primary-mirror segment pair is up with the primary and mirror
        roles reversed from their preferred roles.</p>
      <table frame="all" rowsep="1" colsep="1" id="table_idk_jst_fgb">
        <tgroup cols="5">
          <colspec colname="c1" colnum="1" colwidth="1.0*"/>
          <colspec colname="c2" colnum="2" colwidth="1.0*"/>
          <colspec colname="c3" colnum="3" colwidth="1.0*"/>
          <colspec colname="c4" colnum="4" colwidth="1.0*"/>
          <colspec colname="c5" colnum="5" colwidth="1.0*"/>
          <thead>
            <row>
              <entry/>
              <entry><codeph>preferred_role</codeph></entry>
              <entry><codeph>role</codeph></entry>
              <entry><codeph>mode</codeph></entry>
              <entry><codeph>status</codeph></entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>Primary</entry>
              <entry><codeph>p</codeph><p>(primary)</p></entry>
              <entry><codeph>m</codeph><p>(mirror)</p></entry>
              <entry><codeph>s</codeph><p>(synchronizing)</p></entry>
              <entry><codeph>u</codeph><p>(up)</p></entry>
            </row>
            <row>
              <entry>Mirror</entry>
              <entry><codeph>m</codeph><p>(mirror)</p></entry>
              <entry><codeph>p</codeph><p>(primary)</p></entry>
              <entry><codeph>s</codeph><p>(synchronizing)</p></entry>
              <entry><codeph>u</codeph><p>(up)</p></entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <p>The <codeph>gprecoverseg -r</codeph> command rebalances the system by returning the segment
        roles to their preferred roles.</p>
      <table frame="all" rowsep="1" colsep="1" id="table_jdk_jst_fgb">
        <tgroup cols="5">
          <colspec colname="c1" colnum="1" colwidth="1.0*"/>
          <colspec colname="c2" colnum="2" colwidth="1.0*"/>
          <colspec colname="c3" colnum="3" colwidth="1.0*"/>
          <colspec colname="c4" colnum="4" colwidth="1.0*"/>
          <colspec colname="c5" colnum="5" colwidth="1.0*"/>
          <thead>
            <row>
              <entry/>
              <entry><codeph>preferred_role</codeph></entry>
              <entry><codeph>role</codeph></entry>
              <entry><codeph>mode</codeph></entry>
              <entry><codeph>status</codeph></entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>Primary</entry>
              <entry><codeph>p</codeph><p>(primary)</p></entry>
              <entry><codeph>p</codeph><p>(primary)</p></entry>
              <entry><codeph>s</codeph><p>(synchronized)</p></entry>
              <entry><codeph>u</codeph><p>(up)</p></entry>
            </row>
            <row>
              <entry>Mirror</entry>
              <entry><codeph>m</codeph><p>(mirror)</p></entry>
              <entry><codeph>m</codeph><p>(mirror)</p></entry>
              <entry><codeph>s</codeph><p>(synchronized)</p></entry>
              <entry><codeph>u</codeph><p>(up)</p></entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
    <section>
      <title>Configuring FTS Behavior</title>
      <p>There is a set of server configuration parameters that affect FTS behavior:<parml>
          <plentry>
            <pt>gp_fts_probe_interval</pt>
            <pd>How often, in seconds, to begin a new FTS loop. For example if the setting is 60 and
              the probe loop takes 10 seconds, the FTS process sleeps 50 seconds. If the setting is
              60 and probe loop takes 75 seconds, the process sleeps 0 seconds. The default is 60,
              and the maximum is 3600. </pd>
          </plentry>
          <plentry>
            <pt>gp_fts_probe_timeout</pt>
            <pd>Probe timeout between master and segment, in seconds. The default is 20, and the
              maximum is 3600. </pd>
          </plentry>
          <plentry>
            <pt>gp_fts_probe_retries</pt>
            <pd>The number of attempts to probe a segment. For example if the setting is 5 there
              will be 4 retries after the first attempt fails. Default: 5 </pd>
          </plentry>
          <plentry>
            <pt>gp_log_fts</pt>
            <pd>Logging level for FTS. The value may be "off", "terse", "verbose", or "debug". The
              "verbose" setting can be used in production to provide useful data for
              troubleshooting. The "debug" setting should not be used in production. Default:
              "terse"</pd>
          </plentry>
          <plentry>
            <pt>gp_segment_connect_timeout</pt>
            <pd>The maximum time (in seconds) allowed for a mirror to respond. Default: 180 (3
              minutes)</pd>
          </plentry>
        </parml></p>
      <p>In addition to the fault checking performed by the FTS, a primary segment that is unable to
        send data to its mirror can change the status of the mirror to down. The primary queues up
        the data and after <codeph>gp_segment_connect_timeout</codeph> seconds passes, indicates a
        mirror failure, causing the mirror to be marked down and the primary to go into change
        tracking mode.</p>
    </section>
  </body>
</topic>
