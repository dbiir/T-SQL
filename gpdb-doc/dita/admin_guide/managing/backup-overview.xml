<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="backup-restore-over">
  <title>Backup and Restore Overview</title>
  <body>
    <p>Greenplum Database supports parallel and non-parallel methods for backing up and restoring
      databases. Parallel operations scale regardless of the number of segments in your system,
      because segment hosts each write their data to local disk storage simultaneously. With
      non-parallel backup and restore operations, the data must be sent over the network from the
      segments to the master, which writes all of the data to its storage. In addition to
      restricting I/O to one host, non-parallel backup requires that the master have sufficient
      local disk storage to store the entire database. </p>
    <section>
      <title>Parallel Backup with gpbackup and gprestore</title>
      <p><codeph>gpbackup</codeph> and <codeph>gprestore</codeph> are the Greenplum Database
        backup and restore utilities. <codeph>gpbackup</codeph>
        utilizes <codeph>ACCESS SHARE</codeph> locks at the individual table level, instead of
          <codeph>EXCLUSIVE</codeph> locks on the <codeph>pg_class</codeph> catalog table. This
        enables you to execute DML statements during the backup, such as <codeph>CREATE</codeph>,
          <codeph>ALTER</codeph>,  <codeph>DROP</codeph>, and <codeph>TRUNCATE</codeph> operations,
        as long as those operations do not target the current backup set. </p>
      <p>Backup files created with <codeph>gpbackup</codeph> are designed to provide future
        capabilities for restoring individual database objects along with their dependencies, such
        as functions and required user-defined datatypes. See <xref
          href="backup-gpbackup.xml#topic_yrr_hqw_sbb"/> for more information.</p>
    </section>
    <section>
      <title id="kk155276">Non-Parallel Backup with pg_dump</title>
      <p>The PostgreSQL <codeph>pg_dump</codeph> and <codeph>pg_dumpall</codeph> non-parallel backup
        utilities can be used to create a single dump file on the master host that contains all data
        from all active segments. </p>
      <p>The PostgreSQL non-parallel utilities should be used only for special cases. They are much
        slower than using the Greenplum backup utilities since all of the data must pass through the
        master. Additionally, it is often the case that the master host has insufficient disk space
        to save a backup of an entire distributed Greenplum database. </p>
      <p>The <codeph>pg_restore</codeph> utility requires compressed dump files created by
          <codeph>pg_dump</codeph> or <codeph>pg_dumpall</codeph>. Before starting the restore, you
        should modify the <codeph>CREATE TABLE</codeph> statements in the dump files to include the
        Greenplum <codeph>DISTRIBUTED</codeph> clause. If you do not include the
          <codeph>DISTRIBUTED</codeph> clause, Greenplum Database assigns default values, which may
        not be optimal. For details, see <codeph>CREATE TABLE</codeph> in the <i>Greenplum Database
          Reference Guide</i>.</p>
      <p>To perform a non-parallel restore using parallel backup files, you can copy the backup
        files from each segment host to the master host, and then load them through the master.</p>
      <fig id="kk156418">
        <title>Non-parallel Restore Using Parallel Backup Files</title>
        <image href="../graphics/nonpar_restore.jpg" placement="break" width="390px"
          height="231px" id="image_dyn_qhx_yq"/>
      </fig>
      <p>Another non-parallel method for backing up Greenplum Database data is to use the
          <codeph>COPY TO</codeph> SQL command to copy all or a portion of a table out of the
        database to a delimited text file on the master host. </p>
    </section>
  </body>
</topic>
