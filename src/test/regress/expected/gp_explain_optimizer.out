create schema gpexplain;
set search_path = gpexplain;
-- Helper function, to return the EXPLAIN output of a query as a normal
-- result set, so that you can manipulate it further.
create or replace function get_explain_output(explain_query text) returns setof text as
$$
declare
  explainrow text;
begin
  for explainrow in execute 'EXPLAIN ' || explain_query
  loop
    return next explainrow;
  end loop;
end;
$$ language plpgsql;
-- Same, for EXPLAIN ANALYZE VERBOSE
create or replace function get_explain_analyze_output(explain_query text) returns setof text as
$$
declare
  explainrow text;
begin
  for explainrow in execute 'EXPLAIN (ANALYZE, VERBOSE) ' || explain_query
  loop
    return next explainrow;
  end loop;
end;
$$ language plpgsql;
--
-- Test explain_memory_verbosity option
-- 
CREATE TABLE explaintest (id int4);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'id' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
INSERT INTO explaintest SELECT generate_series(1, 10);
EXPLAIN ANALYZE SELECT * FROM explaintest;
                                                        QUERY PLAN                                                        
--------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=0.00..431.00 rows=10 width=4) (actual time=0.365..0.380 rows=10 loops=1)
   ->  Seq Scan on explaintest  (cost=0.00..431.00 rows=4 width=4) (actual time=0.019..0.021 rows=5 loops=1)
   (slice0)    Executor memory: 290K bytes.
   (slice1)    Executor memory: 135K bytes avg x 3 workers, 135K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Pivotal Optimizer (GPORCA) version 2.55.21
 Total runtime: 0.710 ms
(7 rows)

set explain_memory_verbosity='summary';
-- The plan should consist of a Gather and a Seq Scan, with a
-- "Memory: ..." line on both nodes.
SELECT COUNT(*) from
  get_explain_analyze_output($$
    SELECT * FROM explaintest;
  $$) as et
WHERE et like '%Memory: %';
 count 
-------
     2
(1 row)

reset explain_memory_verbosity;
EXPLAIN ANALYZE SELECT id FROM 
( SELECT id 
	FROM explaintest
	WHERE id > (
		SELECT avg(id)
		FROM explaintest
	)
) as foo
ORDER BY id
LIMIT 1;
                                                                                QUERY PLAN                                                                                 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..1324033.14 rows=1 width=4) (actual time=51.066..51.068 rows=1 loops=1)
   ->  Gather Motion 3:1  (slice3; segments: 3)  (cost=0.00..1324033.14 rows=1 width=4) (actual time=51.063..51.063 rows=1 loops=1)
         Merge Key: explaintest.id
         ->  Limit  (cost=0.00..1324033.14 rows=1 width=4) (actual time=16.459..16.468 rows=1 loops=1)
               ->  Sort  (cost=0.00..1324033.14 rows=4 width=4) (actual time=16.456..16.456 rows=1 loops=1)
                     Sort Key: explaintest.id
                     Sort Method:  top-N heapsort  Memory: 51kB
                     ->  Nested Loop  (cost=0.00..1324033.14 rows=4 width=4) (actual time=5.958..5.963 rows=3 loops=1)
                           Join Filter: ((explaintest.id)::numeric > (pg_catalog.avg((avg(explaintest_1.id)))))
                           ->  Broadcast Motion 1:3  (slice2)  (cost=0.00..431.00 rows=3 width=8) (actual time=15.840..15.841 rows=1 loops=1)
                                 ->  Aggregate  (cost=0.00..431.00 rows=1 width=8) (actual time=4.496..4.496 rows=1 loops=1)
                                       ->  Gather Motion 3:1  (slice1; segments: 3)  (cost=0.00..431.00 rows=1 width=8) (actual time=0.010..4.456 rows=3 loops=1)
                                             ->  Aggregate  (cost=0.00..431.00 rows=1 width=8) (actual time=0.057..0.057 rows=1 loops=1)
                                                   ->  Seq Scan on explaintest explaintest_1  (cost=0.00..431.00 rows=4 width=4) (actual time=0.047..0.048 rows=5 loops=1)
                           ->  Seq Scan on explaintest  (cost=0.00..431.00 rows=4 width=4) (actual time=0.003..0.017 rows=3 loops=2)
 Planning time: 63.227 ms
   (slice0)    Executor memory: 156K bytes.
   (slice1)    Executor memory: 60K bytes avg x 3 workers, 60K bytes max (seg0).
   (slice2)    Executor memory: 167K bytes (entry db).
 * (slice3)    Executor memory: 124K bytes avg x 3 workers, 124K bytes max (seg0).  Work_mem: 65K bytes max, 1K bytes wanted.
 Memory used:  256000kB
 Memory wanted:  1001kB
 Optimizer: Pivotal Optimizer (GPORCA) version 3.61.0
 Execution time: 131.741 ms
(24 rows)

-- Verify that the column references are OK. This tests for an old ORCA bug,
-- where the Filter clause in the IndexScan of this query was incorrectly
-- printed as something like:
--
--   Filter: "outer".column2 = mpp22263.*::text
CREATE TABLE mpp22263 (
        unique1         int4,
        unique2         int4,
        two                     int4,
        four            int4,
        ten                     int4,
        twenty          int4,
        hundred         int4,
        thousand        int4,
        twothousand     int4,
        fivethous       int4,
        tenthous        int4,
        odd                     int4,
        even            int4,
        stringu1        name,
        stringu2        name,
        string4         name
) distributed by (unique1);
create index mpp22263_idx1 on mpp22263 using btree(unique1);
explain select * from mpp22263, (values(147, 'RFAAAA'), (931, 'VJAAAA')) as v (i, j)
WHERE mpp22263.unique1 = v.i and mpp22263.stringu1 = v.j;
                                         QUERY PLAN                                         
--------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=0.00..2.00 rows=1 width=256)
   ->  Nested Loop  (cost=0.00..2.00 rows=1 width=256)
         Join Filter: true
         ->  Result  (cost=0.00..0.00 rows=1 width=12)
               ->  Values Scan on "Values"  (cost=0.00..0.00 rows=1 width=12)
         ->  Index Scan using mpp22263_idx1 on mpp22263  (cost=0.00..2.00 rows=1 width=244)
               Index Cond: unique1 = "Values".column1
               Filter: stringu1::text = "Values".column2
 Optimizer: Pivotal Optimizer (GPORCA) version 2.64.0
(9 rows)

-- atmsort.pm masks out differences in the Filter line, so just memorizing
-- the output of the above EXPLAIN isn't enough to catch a faulty Filter line.
-- Extract the Filter explicitly.
SELECT * from
  get_explain_output($$
select * from mpp22263, (values(147, 'RFAAAA'), (931, 'VJAAAA')) as v (i, j)
WHERE mpp22263.unique1 = v.i and mpp22263.stringu1 = v.j;
  $$) as et
WHERE et like '%Filter: %';
                             et                              
-------------------------------------------------------------
         Join Filter: true
               Filter: ((stringu1)::text = "Values".column2)
(2 rows)

--
-- Join condition in explain plan should represent constants with proper
-- variable name
--
create table foo (a int) distributed randomly;
-- "outer", "inner" prefix must also be prefixed to variable name as length of rtable > 1
SELECT trim(et) et from
get_explain_output($$ 
	select * from (values (1)) as f(a) join (values(2)) b(b) on a = b join foo on true join foo as foo2 on true $$) as et
WHERE et like '%Join Filter:%' or et like '%Hash Cond:%';
                       et                       
------------------------------------------------
 Join Filter: true
 Join Filter: true
 Hash Cond: ("outer".column1 = "outer".column1)
(3 rows)

SELECT trim(et) et from
get_explain_output($$
	select * from (values (1)) as f(a) join (values(2)) b(b) on a = b$$) as et
WHERE et like '%Hash Cond:%';
               et               
--------------------------------
 Hash Cond: (column1 = column1)
(1 row)

--
-- Test EXPLAINing of the Partition By in a window function. (PostgreSQL
-- doesn't print it at all.)
--
explain (costs off) select count(*) over (partition by g) from generate_series(1, 10) g;
                     QUERY PLAN                     
----------------------------------------------------
 Result
   ->  WindowAgg
         Partition By: generate_series
         ->  Sort
               Sort Key: generate_series
               ->  Function Scan on generate_series
 Optimizer: Pivotal Optimizer (GPORCA) version 2.70.0
(7 rows)

--
-- Test non-text format with a few queries that contain GPDB-specific node types.
--
-- The default init_file rules contain a line to mask this out in normal
-- text-format EXPLAIN output, but it doesn't catch these alternative formats.
-- start_matchignore
-- m/Optimizer.*Pivotal Optimizer \(GPORCA\) version .*/
-- end_matchignore
CREATE EXTERNAL WEB TABLE dummy_ext_tab (x text) EXECUTE 'echo foo' FORMAT 'text';
-- External Table Scan
explain (format json, costs off) SELECT * FROM dummy_ext_tab;
                 QUERY PLAN                  
---------------------------------------------
 [                                                             +
   {                                                           +
     "Plan": {                                                 +
       "Node Type": "Gather Motion",                           +
       "Senders": 3,                                           +
       "Receivers": 1,                                         +
       "Slice": 1,                                             +
       "Segments": 3,                                          +
       "Gang Type": "primary reader",                          +
       "Plans": [                                              +
         {                                                     +
           "Node Type": "External Scan",                       +
           "Parent Relationship": "Outer",                     +
           "Slice": 1,                                         +
           "Segments": 3,                                      +
           "Gang Type": "primary reader",                      +
           "Relation Name": "dummy_ext_tab",                   +
           "Alias": "dummy_ext_tab"                            +
         }                                                     +
       ]                                                       +
     },                                                        +
     "Settings": {                                             +
       "Optimizer": "Pivotal Optimizer (GPORCA) version 2.70.0"+
     }                                                         +
   }                                                           +
 ]
(1 row)

-- Seq Scan on an append-only table
CREATE TEMP TABLE dummy_aotab (x int4) WITH (appendonly=true);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'x' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
explain (format yaml, costs off) SELECT * FROM dummy_aotab;
              QUERY PLAN              
--------------------------------------
 - Plan:                                                   +
     Node Type: "Gather Motion"                            +
     Senders: 3                                            +
     Receivers: 1                                          +
     Slice: 1                                              +
     Segments: 3                                           +
     Gang Type: "primary reader"                           +
     Plans:                                                +
       - Node Type: "Seq Scan"                             +
         Parent Relationship: "Outer"                      +
         Slice: 1                                          +
         Segments: 3                                       +
         Gang Type: "primary reader"                       +
         Relation Name: "dummy_aotab"                      +
         Alias: "dummy_aotab"                              +
   Settings:                                               +
     Optimizer: "Pivotal Optimizer (GPORCA) version 2.70.0"
(1 row)

-- DML node (with ORCA)
explain (format xml, costs off) insert into dummy_aotab values (1);
                               QUERY PLAN                               
------------------------------------------------------------------------
 <explain xmlns="http://www.postgresql.org/2009/explain">              +
   <Query>                                                             +
     <Plan>                                                            +
       <Node-Type>DML</Node-Type>                                      +
       <Operation>Insert</Operation>                                   +
       <Slice>0</Slice>                                                +
       <Segments>1</Segments>                                          +
       <Gang-Type>primary writer</Gang-Type>                           +
       <Plans>                                                         +
         <Plan>                                                        +
           <Node-Type>Result</Node-Type>                               +
           <Parent-Relationship>Outer</Parent-Relationship>            +
           <Slice>0</Slice>                                            +
           <Segments>1</Segments>                                      +
           <Gang-Type>primary writer</Gang-Type>                       +
           <Plans>                                                     +
             <Plan>                                                    +
               <Node-Type>Result</Node-Type>                           +
               <Parent-Relationship>Outer</Parent-Relationship>        +
               <Slice>0</Slice>                                        +
               <Segments>1</Segments>                                  +
               <Gang-Type>primary writer</Gang-Type>                   +
               <Plans>                                                 +
                 <Plan>                                                +
                   <Node-Type>Result</Node-Type>                       +
                   <Parent-Relationship>Outer</Parent-Relationship>    +
                   <Slice>0</Slice>                                    +
                   <Segments>1</Segments>                              +
                   <Gang-Type>primary writer</Gang-Type>               +
                   <Plans>                                             +
                     <Plan>                                            +
                       <Node-Type>Result</Node-Type>                   +
                       <Parent-Relationship>Outer</Parent-Relationship>+
                       <Slice>0</Slice>                                +
                       <Segments>1</Segments>                          +
                       <Gang-Type>primary writer</Gang-Type>           +
                     </Plan>                                           +
                   </Plans>                                            +
                 </Plan>                                               +
               </Plans>                                                +
             </Plan>                                                   +
           </Plans>                                                    +
         </Plan>                                                       +
       </Plans>                                                        +
     </Plan>                                                           +
     <Settings>                                                        +
       <Optimizer>Pivotal Optimizer (GPORCA) version 2.70.0</Optimizer>                       +
     </Settings>                                                       +
   </Query>                                                            +
 </explain>
(1 row)

-- github issues 5795. explain fails previously.
explain SELECT * from information_schema.key_column_usage;
                                                                   QUERY PLAN                                                                    
-------------------------------------------------------------------------------------------------------------------------------------------------
 Hash Join  (cost=102.67..1432.09 rows=13 width=389)
   Hash Cond: ((ss.roid = a.attrelid) AND ((ss.x).x = a.attnum))
   Join Filter: (pg_has_role(ss.relowner, 'USAGE'::text) OR has_column_privilege(ss.roid, a.attnum, 'SELECT, INSERT, UPDATE, REFERENCES'::text))
   ->  Subquery Scan on ss  (cost=3.34..106.09 rows=5825 width=333)
         ->  Result  (cost=3.34..47.85 rows=5825 width=341)
               ->  Hash Join  (cost=3.34..47.85 rows=5825 width=341)
                     Hash Cond: (c.connamespace = nc.oid)
                     ->  Hash Join  (cost=2.19..16.06 rows=6 width=281)
                           Hash Cond: (r.relnamespace = nr.oid)
                           ->  Hash Join  (cost=1.04..14.84 rows=7 width=221)
                                 Hash Cond: (r.oid = c.conrelid)
                                 ->  Seq Scan on pg_class r  (cost=0.00..13.41 rows=85 width=76)
                                       Filter: (relkind = 'r'::"char")
                                 ->  Hash  (cost=1.03..1.03 rows=1 width=149)
                                       ->  Seq Scan on pg_constraint c  (cost=0.00..1.03 rows=1 width=149)
                                             Filter: (contype = ANY ('{p,u,f}'::"char"[]))
                           ->  Hash  (cost=1.09..1.09 rows=2 width=68)
                                 ->  Seq Scan on pg_namespace nr  (cost=0.00..1.09 rows=5 width=68)
                                       Filter: (NOT pg_is_other_temp_schema(oid))
                     ->  Hash  (cost=1.07..1.07 rows=3 width=68)
                           ->  Seq Scan on pg_namespace nc  (cost=0.00..1.07 rows=7 width=68)
   ->  Hash  (cost=49.33..49.33 rows=1111 width=70)
         ->  Seq Scan on pg_attribute a  (cost=0.00..49.33 rows=3333 width=70)
               Filter: (NOT attisdropped)
 Optimizer: Postgres query optimizer
(25 rows)

-- github issue 5794.
set gp_enable_explain_allstat=on;
explain analyze SELECT * FROM explaintest;
                                                          QUERY PLAN                                                           
-------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)  (cost=0.00..431.00 rows=10 width=4) (actual time=0.298..0.302 rows=5 loops=2)
   ->  Seq Scan on explaintest  (cost=0.00..431.00 rows=4 width=4) (actual time=0.013..0.015 rows=2 loops=2)
         allstat: seg_firststart_total_ntuples/seg0_0.938 ms_0.027 ms_3/seg1_0.880 ms_0.029 ms_5/seg2_0.866 ms_0.029 ms_2//end
   (slice0)    Executor memory: 290K bytes.
   (slice1)    Executor memory: 50K bytes avg x 3 workers, 50K bytes max (seg0).
 Memory used:  128000kB
 Optimizer: Pivotal Optimizer (GPORCA) version 3.2.0
 Total runtime: 1.577 ms
(8 rows)

set gp_enable_explain_allstat=DEFAULT;
