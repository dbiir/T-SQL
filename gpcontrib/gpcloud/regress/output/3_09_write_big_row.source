CREATE WRITABLE EXTERNAL TABLE s3write_bigrow_write (id serial, content text)
        LOCATION('s3://s3-us-west-2.amazonaws.com/@write_prefix@/bigrow/ config=@config_file@') FORMAT 'csv';
-- Pangram: 'Pack my box with five dozen liquor jugs.' 40 chars, 32 letters
-- Total 40KB
INSERT INTO s3write_bigrow_write VALUES (DEFAULT,
  repeat('Pack my box with five dozen liquor jugs.', 1024 ));
-- Total 40MB
INSERT INTO s3write_bigrow_write VALUES (DEFAULT,
  repeat('Pack my box with five dozen liquor jugs.', 1024 * 1024));
-- Total 80MB
INSERT INTO s3write_bigrow_write VALUES (DEFAULT,
  repeat('Pack my box with five dozen liquor jugs.', 1024 * 1024 * 2));
-- Total 200MB
-- INSERT INTO s3write_bigrow_write VALUES (DEFAULT,
--   repeat('Pack my box with five dozen liquor jugs.', 1024 * 1024 * 5));
-- Total 320MB, CRASH!! Report on https://github.com/greenplum-db/gpdb/issues/1090
-- INSERT INTO s3write_bigrow_write VALUES (DEFAULT,
--   repeat('Pack my box with five dozen liquor jugs.', 1024 * 1024 * 8));
DROP EXTERNAL TABLE IF EXISTS s3write_bigrow_write;
